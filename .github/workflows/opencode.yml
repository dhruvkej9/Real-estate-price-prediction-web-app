name: opencode

on:
  issue_comment:
    types: [created]
  pull_request_review_comment:
    types: [created]

jobs:
  opencode:
    if: |
      github.actor != 'opencode-agent[bot]' &&
      (
        contains(github.event.comment.body, ' /oc') ||
        startsWith(github.event.comment.body, '/oc') ||
        contains(github.event.comment.body, ' /opencode') ||
        startsWith(github.event.comment.body, '/opencode')
      )
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: write
      pull-requests: write
      issues: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          fetch-depth: 1
          persist-credentials: false

      - name: Write OpenCode auth.json
        shell: bash
        run: |
          mkdir -p ~/.local/share/opencode
          echo "${{ secrets.OPENCODE_AUTH_JSON_B64 }}" | base64 -d > ~/.local/share/opencode/auth.json
          chmod 600 ~/.local/share/opencode/auth.json

      - name: Clone and start local proxy
        shell: bash
        run: |
          git clone --depth 1 https://github.com/dhruvkej9/opencode-local-proxy.git /tmp/opencode-local-proxy
          cd /tmp/opencode-local-proxy
          export OPENCODE_PROXY_PORT=4318
          node proxy.mjs &
          sleep 3
          curl -s http://127.0.0.1:4318/health

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2

      - name: Configure OpenCode variant
        shell: bash
        run: |
          mkdir -p ~/.config/opencode
          cat > ~/.config/opencode/opencode.json <<'JSON'
          {
            "$schema": "https://opencode.ai/config.json",
            "model": "local-proxy/kimi-k2.5-free",
            "agent": {
              "build": {
                "model": "local-proxy/kimi-k2.5-free",
                "variant": "high",
                "prompt": "Use ripgrep (rg) instead of grep/glob/find for searching. Commands: rg 'pattern' (search content), rg --files (list all files), rg --files -g '*.ext' (filter by extension), rg --files -g '*.{js,py,md}' (multiple extensions), rg 'pattern' -g '*.ext' (search in specific file types), rg -i 'pattern' (case insensitive), rg -C 3 'pattern' (show 3 lines context). ripgrep is faster and respects .gitignore by default. Use context7 for latest package info.\n\nUse websearch when local context is insufficient. At least one websearch is recommended for each task before finalizing.\n\nYou are an AI agent with persistent memory powered by SuperMemory MCP (mcp.supermemory.ai).\n\nMemory rules:\n- Before responding, call supermemory_recall only when the request benefits from past context (preferences, prior decisions, project history, recurring issues).\n- Skip recall for direct mechanical actions that already contain full context (e.g., explicit save/forget memory commands, simple one-shot confirmations).\n- Prioritize the most recent and most relevant memories; if nothing useful is found, continue normally.\n- Store memory with supermemory_memory only when there is durable value.\n- Save only durable learnings, reusable patterns, and solved-issue knowledge (root cause + fix).\n- Do not save task logs, todos, progress updates, generic work-completed notes, or low-value status noise.\n- Update incrementally; avoid overwriting prior memory unless explicitly instructed.\n\nWorkflow:\n1) Recall relevant context when useful.\n2) Reason using recalled context plus current input.\n3) Save durable insights if any.\n4) Respond concisely and personalize using recalled memory when relevant.\n\nFallback:\n- If supermemory tools fail, continue and include a concise memory-candidate summary for later storage.\n\nUse MCP tools intentionally:\n- Use chrome-devtools MCP for browser debugging, performance bottlenecks, network waterfall, runtime errors, DOM/CSS inspection, and rendering issues.\n- For frontend or integration fixes, validate behavior and include what you verified in your response."
              }
            },
            "watcher": {
              "ignore": [
                "node_modules/**",
                "dist/**",
                ".git/**"
              ]
            },
            "mcp": {
              "supermemory": {
                "type": "remote",
                "url": "https://mcp.supermemory.ai/mcp",
                "headers": {
                  "Authorization": "Bearer ${{ secrets.SUPERMEMORY_API_KEY }}"
                },
                "enabled": true
              },
              "chrome-devtools": {
                "type": "local",
                "command": [
                  "npx",
                  "-y",
                  "chrome-devtools-mcp@latest",
                  "--headless",
                  "--isolated",
                  "--chromeArg=--no-sandbox",
                  "--chromeArg=--disable-dev-shm-usage",
                  "--logFile=/tmp/chrome-devtools-mcp.log"
                ],
                "enabled": true
              }
            },
            "lsp": false,
            "permission": {
              "external_directory": "allow",
              "question": "allow",
              "*": "allow"
            },
            "provider": {
              "local-proxy": {
                "npm": "@ai-sdk/openai-compatible",
                "name": "Local Proxy (Free Models + Codex Fallback)",
                "options": {
                  "baseURL": "http://127.0.0.1:4318/v1",
                  "apiKey": "public"
                },
                "models": {
                  "kimi-k2.5-free": {
                    "name": "Kimi K2.5 Free",
                    "limit": { "context": 262000, "output": 32768 },
                    "modalities": { "input": ["text", "image"], "output": ["text"] }
                  },
                  "glm-5-free": {
                    "name": "GLM-5 Free",
                    "limit": { "context": 200000, "output": 128000 },
                    "modalities": { "input": ["text", "image"], "output": ["text"] }
                  },
                  "gpt-5.3-codex": {
                    "name": "GPT-5.3 Codex (Fallback)",
                    "limit": { "context": 272000, "output": 128000 },
                    "modalities": { "input": ["text", "image"], "output": ["text"] }
                  }
                }
              }
            }
          }
          JSON

      - name: Run OpenCode
        uses: anomalyco/opencode/github@latest
        env:
          OPENCODE_PERMISSION: '{"*": "allow"}'
        with:
          model: local-proxy/kimi-k2.5-free
